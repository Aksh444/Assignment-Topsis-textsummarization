# -*- coding: utf-8 -*-
"""Untitled

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Kd_axc-wSkkNkzrLdA32t7udfYGe7Elb
"""

!pip install transformers numpy pandas scikit-learn rouge-score matplotlib seaborn

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from transformers import pipeline
from sklearn.preprocessing import MinMaxScaler
from rouge_score import rouge_scorer

# Pre-trained text summarization models
models = [
    "facebook/bart-large-cnn",
    "google/pegasus-xsum",
    "t5-small",
    "sshleifer/distilbart-cnn-12-6"
]

# Sample text for summarization
text = """Artificial Intelligence (AI) is transforming industries by automating processes, enhancing decision-making, and enabling innovative applications.
It is widely used in healthcare, finance, transportation, and more. AI technologies such as machine learning and deep learning
are driving this transformation, making systems smarter and more efficient."""

# Ground truth summary (for evaluation)
ground_truth = "AI is revolutionizing industries with automation and better decision-making, impacting healthcare, finance, and more."

# Function to evaluate ROUGE score
def evaluate_summary(predicted, reference):
    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)
    scores = scorer.score(predicted, reference)
    return scores['rouge1'].fmeasure, scores['rouge2'].fmeasure, scores['rougeL'].fmeasure

# Store results
results = []

for model in models:
    summarizer = pipeline("summarization", model=model)
    summary = summarizer(text, max_length=50, min_length=10, do_sample=False)[0]['summary_text']

    rouge1, rouge2, rougeL = evaluate_summary(summary, ground_truth)
    results.append([model, rouge1, rouge2, rougeL])

# Convert results into a DataFrame
df = pd.DataFrame(results, columns=['Model', 'ROUGE-1', 'ROUGE-2', 'ROUGE-L'])

# Normalize the values using Min-Max Scaling for TOPSIS
scaler = MinMaxScaler()
df[['ROUGE-1', 'ROUGE-2', 'ROUGE-L']] = scaler.fit_transform(df[['ROUGE-1', 'ROUGE-2', 'ROUGE-L']])

# Compute TOPSIS score
ideal_best = df[['ROUGE-1', 'ROUGE-2', 'ROUGE-L']].max().values
ideal_worst = df[['ROUGE-1', 'ROUGE-2', 'ROUGE-L']].min().values

# Euclidean distance from best and worst
df['S+'] = np.sqrt(((df[['ROUGE-1', 'ROUGE-2', 'ROUGE-L']] - ideal_best) ** 2).sum(axis=1))
df['S-'] = np.sqrt(((df[['ROUGE-1', 'ROUGE-2', 'ROUGE-L']] - ideal_worst) ** 2).sum(axis=1))

# TOPSIS Score
df['TOPSIS Score'] = df['S-'] / (df['S+'] + df['S-'])

# Rank models
df['Rank'] = df['TOPSIS Score'].rank(ascending=False)

# Plot results
plt.figure(figsize=(10, 6))
sns.barplot(x=df['Model'], y=df['TOPSIS Score'], palette="viridis")
plt.xlabel("Model")
plt.ylabel("TOPSIS Score")
plt.title("TOPSIS Score of Pre-trained Text Summarization Models")
plt.xticks(rotation=45)
plt.show()

# Display final table
print(df[['Model', 'ROUGE-1', 'ROUGE-2', 'ROUGE-L', 'TOPSIS Score', 'Rank']])



